\chapter{Introduction}

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
I used the following stuff: \cite{A1}, \cite{DETERM_WKA}, \cite{A3}, \cite{A4}, \cite{A5}, \cite{A6}, \cite{A7}, \cite{WK_CYK}, \cite{WK_PUSHDOWN_AUT}, \cite{WK_FIN_AUT}


\chapter{Watson-Crick models and DNA}
The study of Watson-Crick models is motivated by DNA (deoxyribonucleic acid) computing. In order to study the DNA mathematically -- i.e. to perform mathematical operations, it is necessary to work with a suitable abstraction -- a model which captures its key characteristics. Specifically, there are two characterictics that the Watson-Crick models capture -- the fact that DNA is a double stranded chain and the Watson-Crick relation between DNA nucleotides.
The two fundamental models that are used to define a language in computer theory are grammars and automata. Several versions of both have been proposed but all of them work with these two characterictics in a very similar manner.

\begin{figure}
  \includegraphics[width=8cm]{placeholder.pdf}
  \centering
  \caption{The DNA double helix}
\end{figure}

DNA consists of two chains of nucleotides that are connected by covalent bonds and together form a double helix. These two chains are represented in the Watson-Crick automata by two reading heads which read two inputs independetly but controlled by the same states. Similarly, Watson-Crick grammars produce by their rules not just a chain of symbols, but two chains.

Each nucleotide contains one of the four nucleobases - cytosine (C), guanine (G), adenine (A), thymine (T). These bases are always connected with their counterpart: cytosine with guanine and adenine with thymine. That means that whenever one of the four appears in a chain, its counterpart appears in the other chain in the corresponding place being bound together by the covalent bond. The Watson-Crick models therefore introduce a complementary relation -- a relation between symbols which must be kept in the whole input for it to be valid. Typically, this relation is symmetric ($a R b \Leftrightarrow b R a$) and covers the whole alphabet (every symbol must have at least one counterpart). Often every symbol has exactly one counterpart -- just like in case of DNA (the relation is frequently defined as an identity which is still somewhat similar to the DNA pairing).

\chapter{Watson-Crick models}
Number of models working with double stranded sequences has been proposed. The purpuse of this chapter is to summarize these models and some of their key attributes that will be used in a later chapters.


\section{Watson-Crick automata}
Watson-Crick automata have been first proposed in \cite{WK_FIN_AUT} as an enhancement of standard Finite Automata. Watson-Crick finite automaton is a 6-tuple $M = (V, \rho, Q, q_0, F, P)$ with the following meaning.
\begin{itemize}
  \item{$V$ -- finite input alphabet}
  \item{$\rho \subseteq V \times V$ -- complementarity relation}
  \item{$Q$ -- finite set of states}
  \item{$q_0 \in Q$ -- starting symbol}
  \item{$F \subseteq Q$ -- set of finite states}
  \item{$P$ -- finite set of transition rules in a form $q({w_1 \atop w_2}) \rightarrow q'$ where $q, q' \in Q, w_1, w_2 \in V^*$}
\end{itemize}

Compared to Finite automata, Watson-Crick automata have different form of transition rules which read two strings at the same time. These represent the two independent reading heads -- one reading the upper strand ($w_1$) and the other reading the lower strand ($w_2$). They also add the complementarity relation which is usually required to be symmetric. The symbols in the upper and lower strands with the same indices need to adhere to it.

A Watson-Crick domain is a set $WK_{\rho}(V)$ which denotes all valid double strands associated with a given $V$ and $\rho$. Formally:
\begin{align}
	WK_{\rho}(V) = \wkdomain{V}{V}_{\rho}^{*} && \textnormal{where} && \wkdomain{V}{V}_{\rho} = \Big\{\wkdomain{a}{b} | a, b \in V, (a, b) \in \rho \Big\}
\end{align}
This implies that both strands have the same length.

A configuraion of a Watson-Crick automaton is a pair $(q, ({w_1 \atop w_2}))$ where $q \in Q$ is a current state and $w_1, w_2 \in V^*$ are the parts of the upper and lower strands yet to be read.

If $q\big({u_1 \atop u_2}\big) \rightarrow q' \in P$ and $\big({u_1 v_1 \atop u_2 v_2}\big) \in \big({V^* \atop V^*}\big)$ then $q\big({u_1 v_1 \atop u_2 v_2}\big) \Rightarrow q'\big({v_1 \atop v_2}\big)$ is a transition of the Watson-Crick automaton. $\Rightarrow^*$ denotes the transitive and reflexive closure of the relation $\Rightarrow$.

A Watson-Crick automaton accepts the language $L(M)$:

$$L(M) = \Big\{w_1 \in V^* | q_0 \wkdomain{w_1}{w_2} \Rightarrow^* f \genfrac{(}{)}{0pt}{1}{\lambda}{\lambda} \textnormal{ where } f \in F, w_2 \in V^*, \wkdomain{w_1}{w_2} \in WK_{\rho}(V)\Big\}$$

This means that only the upper strand is accepted by this automaton to the language $L$. The lower strand has just an auxiliary purpose.

\section{Special versions of Watson-Crick automata}
Four special versions of Watson-Crick automata are often used. These are:
\begin{itemize}
  \item{Stateless WKA -- The WKA has only one state: $Q = F = {q_0}$}
  \item{All final WKA -- All the states are final: $Q = F$}
  \item{Simple WKA -- each rule reads only one head: $(q({w_1 \atop w_2}) \rightarrow q' \in P) \Rightarrow (w_1 = \lambda \vee w_2 = \lambda)$}
  \item{1-limited WKA -- similar to Simple WKA but also reads only one symbol at a time: $(q({w_1 \atop w_2}) \rightarrow q' \in P) \Rightarrow |w_1 w_2| = 1$}
\end{itemize}

It has been shown that three of these four special types of WKAs have the same power as the actual WKA, namely all final WKA, simple WKA and 1-limited WKA (stateless WKA is weaker). Therefore one possible approach to decide membership would be to limit the decision algorithm to one of these three types without any loss in expressing power.

There are three different variants of deterministic WKA proposed in \cite{DETERM_WKA}. These are:
\begin{itemize}
  \item{Weakly deterministic WKA -- WKA where in each reachable configuration, there is at most one possible continuation.}
  \item{Deterministic WKA -- for any two rules which lead from the same state, either their upper strands or their lower strands must not be prefix comparable, meaning one is not the prefix of the other. Formally: $(q({u \atop v}) \rightarrow q_1 \in P \wedge q({u' \atop v'}) \rightarrow q_2 \in P) \Rightarrow u \nsim_p u' \vee v \nsim_p v'$ where $\sim_p$ is the relation of prefix comparability}
  \item{Stronly deterministic WKA}
\end{itemize}

It is not specified how to actually achieve weak determinism. In fact, \cite{DETERM_WKA} shows that this property is undecidable. Informally, for a WKA to be weakly deterministic but not deterministic, there must be at least two rules which could both be used in certain configuration (otherwise it would be deterministic). But such a configuration must not be reachable (otherwise it would not be weakly deterministic). The configuration may be unreachable trivially -- by such rules using an unreachable state or a symbols that have no related symbols in the complementarity relation. But a configuration may be unrechable non-trivially, if it is possible to tell how many symbols will be read from each strand before reaching certain state.

Both weakly deterministic and deterministic WKA are in reality not deterministic (in an intuitive sense). Their determinism relies on the fact, that the configuration is known. But that is probably not a typical way how to work with WKA, since WKA decides the membership in a language for the upper strand only. That means that a compatible lower strand has to be found in the process of running the WKA. Theoretically, it is possible to approach this problem by first generating all possible lower strands for the given upper strand based solely on the complementarity relation and afterwards use all these pairs as inputs for the WKA. In such a case the weakly deterministic and deterministic automata would be truly deterministic, however this is clearly not feasible for non-trivial complementarity relations. Therefore, the strongly deterministic WKA is the only one witch is truly deterministic under all circumstances, because the identity relation required leaves no space these types of non-determinism.

\section{Watson-Crick grammars}
There are several WK grammars.


\section{Watson-Crick Pushdown automata}
The Watson-Crick Pushdown automata (WCPDA) have been introduced in \cite{WK_PUSHDOWN_AUT}. It is basically a two-head pushdown automaton with the complementarity relation added on top. Formally a WCPDA $P$ is a 10-tuple $P = (Q, \#, \$, V, \Gamma, \delta, q_0, Z_0, F, \rho)$ with most symbols having the same standard meaning as in conventional Pushdown automaton -- $Q$ is a finite set of states, $V$ is an input alphabet, $\Gamma$ is a stack alphabet, $q_0 \in Q$ is a starting state, $Z_0 \in \Gamma$ is a starting stack symbol and $F \subseteq Q$ is the set of final states. Symbols $\#, \$ \notin V$ are left and right input markers on the two strands. $\rho$ is the complementarity relation similar to standard WKA.

$\delta$ is a set of rules in the following form: $(q, ({w_1 \atop w_2}), x) \rightarrow (q', \gamma) \textnormal{ where } q, q' \in Q, w_1, w_2 \in V^* \cup \#V^* \cup V^*\$ \cup \#V^*\$, x \in \Gamma, \delta \in \Gamma^*$. That means the automaton can transition from state $q$ to $q'$ reading the input $w_1$ with the first head and $w_2$ with the second and go to state $q'$ while putting a string (i.e. 0-n symbols) of the stack symbols onto the stack. The two strands on the input are enclosed in the beginning symbol $\#$ and the closing symbol $\$$, therefore the symbol $\#$ may appear in the begginning of $w_1$ or $w_2$ and similarly the closing symbol $\$$ at the end.




\section{Watson-Crick Context-free systems}

\section{Role of the complementarity relation}

\section{Comparison of expressing power of various models}

\chapter{Existing ways of testing membership in Watson-Crick languages}

\section{Using deterministic automata}

\section{WK-CYK}
The WK-CYK algorithm was introduced in \cite{WK_CYK} and it is an enhancement of the CYK algorithm modified for WK languages.
\subsection{The CYK algorithm}
The CYK algorithm, introduced in \todo{Look up the original paper} is used to decide the membership in a language defined by a context-free grammar which must be in Chomsky normal form.

There is a string and a grammar on the input. The algorithm uses bottom-up parsing. In CNF, there are two kinds of rules (disregarding the $S \rightarrow \epsilon$ rule which is used only to include empty string in the language): $A \rightarrow a$ and $A \rightarrow BC$ where $A, B, C$ are non-terminals and $a$ is a terminal. In the first stage, it analyses the first kind of rules -- each of the symbols from the input string has to be generated by a rule or several rules of this form. Thus it gets a set of candidate non-terminals for each symbol.

In the next stage it uses the second kind of rules -- every non-terminal (except the starting one) has to be generated by such a rule. The algorithm is looking for rules which can generate the candidate non-terminals which have been found in the previous stage. All possible combinations need to be considered, for instance the sequence of non-terminals $ABC$ may be generated by rules $X \rightarrow AB$ and $Y \rightarrow XC$ or by rules $X \rightarrow BC$ and $Y \rightarrow AX$. In this way, the algorithm needs to find all possible ways to generate words of increasing length (all parse trees). Finally, it needs to find a non-terminal that can generate the whole word and it must be the starting non-terminal in the given grammar. If it succeeds, the word given on the input is in the language, otherwise it is not.
A more detailed and formal description can be found in \todo{Look up the original paper}.

The complexity of the CYK algorithm is $O(n^4)$.

\todo{possibly show an example and the triangular visualization}

\subsection{Description of the WK-CYK algorithm}
Just like the CYK algorithm works with grammars in Chomsky normal form (CNF), the WK-CYK algorithm works with WK-Chomsky normal form (WK-CNF) -- a modification of CNF for Watson-Crick grammars. Since WK grammars can have terminals only in upper or lower strand, so the CNF rules which generate terminals have the following form: $A \rightarrow ({a \atop \lambda})$ or $A \rightarrow ({\lambda \atop a})$ where $a$ is a terminal. And the empty rule has the form: $S \rightarrow ({\lambda \atop \lambda})$.

Just like any context free grammar can be transformed to CNF, any WK grammar can be transformed to WK-CNF. The algorithm to do that is analogous to CNF and is described in detail in \cite{WK_CYK}.

\subsection{Results and some issues with WK-CYK}
As mentioned WK-CYK algorithm only works with grammars in CNF. While every context-free WK grammar can be transformed to WK-CNF, it can result in a significantly more complex grammar. In some edge cases, there can even be an explosion in the resulting number of rules while removing the $\lambda$-rules.

The complexity of WK-CYK is said to be $O(n^6)$. That is true in relation to the length of the input string only -- when the number of rules is considered a constant. Otherwise the complexity would be $O(n^7)$ -- there are seven nested loops in the actual implementation while one of them is looping over the rules of the grammar.
In practice the WK-CYK algorithm is feasible for input strings with roughly X symbols.




\section{Using WK Pushdown automata}

\chapter{Testing membership by searching the state tree}
This section will introduce the main algorithm of this thesis for testing memebership in WK context-free languages. The core is a standard Bread-first search algorithm (BFS) and then various optimizations are presented.

Standard BFS starts with a root node. In case of grammars, that is the starting non-terminal symbol. Then the tree is built by applying all possible rules to all possible non-terminals. Each rule application generates a new node. The node is a word which consists of some non-terminals, some terminals in the upper strand and terminals in the lower strand. The node that is the solution needs to meet the following criteria:
\begin{enumerate}
  \item{It contains no non-terminals.}
  \item{The upper and lower strands are of the same length.}
  \item{Each pair of symbols from the upper and lower strands with the same index must be related by the complementarity relation.}
  \item{The upper strand must be equal to the input string.}
\end{enumerate}
If the criteria are met, the algorithm has found the right node and that means the input string is part of the language defined by the grammar.

The BFS algorithm always finds solution if there is one. It finds the optimal solution, which in this case means the shortest sequence of rules that generate the solution. Whether the solution is optimal or not is irrelevant for the membership problem, though. If there is no solution, the algorithm will probably never stop as the state tree is usually infinite. Also, such a tree would grow very rapidly and the solution would usually not be found in a reasonable time frame. Therefore, some optimizations need to be introduced.

\section{Identifing a dead end in the state tree}
A blind BFS would stop seaching a branch only when all non-terminals have been used to generate all possible end words (words with only terminals). But sometimes it is possible to tell in advance that the current words can't lead to the sought after solution. If that is the case the whole branch can be trimmed from the tree. The next part describes various ways of recognizing the dead branches.

\subsection{The word is too long}
A terminal symbol which appears both in the upper or lower strand can never disappear further in the branch. That means that the count of all symbols in upper and in the lower strand must not be grater then the length of the input string. Otherwise the solution can never be reached from that branch.

\subsection{The word including non-terminals is too long}
Non-terminals present a more complex problem because generally, they can be erased. If the grammar contains no $\lambda$-rule (rule of the form $N \rightarrow ({\lambda \atop \lambda})$), it is possible to assign length of 1 to each non-terminal. This length can be applied to the upper or to the lower strand because it is not known which strand will absorb the symbol generated from the non-terminal (there can of course be more symbols to both strands, but one at minimum). This then leads to the following constraint on the word:

$$|upper| + |lower| + |nts| \geq 2 \times |input|$$

where $|upper|$ and $|lower|$ are the counts of terminals in the upper and lower strands, $|nts|$ is the number of non-terminals in the word and $|input|$ is the length of the input string. If this constraint is broken, the word can not lead to the solution and the branch can be trimmed.
In this case, it is assured that the algorithm will always finish. Once all the words within the given length limit have been generated and solution not found, the search will end.

If the grammar contains $\lambda$-rules, the previous constrain cannot be applied. But in this case it is possible to utilize the algorithm for removing $\lambda$-rules (which is described in \cite{WK_CYK}). Also, it is possible to identify which non-terminals can ultimately be erased, these would be assigned the length of 0 and the rest of the non-terminals the length of 1. But in this case, it is not guarenteed that the search will finish (Both of these approaches are implemented in the WK\_CFG class).

Possible optimization of this section would be to calculate how many symbols at minimum can be generated from a given non-terminal and use this more precise value as the length of each non-terminal (instead of just 0 if it can be erased or 1 otherwise).

\subsection{The beginning of the word does not match the input}
If the current word begins with some terminal symbols in the upper strand, these symbols will always stay at the beginning further in the given branch. If these symbols do not match the prefix of the input string of the same length, the input string can never be generated from this branch.

If on the other hand, the word starts with a non-terminal, there is nothing to be said about what can be at the beginning of the word futher in the branch.

It is possible to check the end of the word in the same manner, but as it will be described futher, the generation is performed from the left to the right and so there is no benefit in checking the end.

\subsection{Checking the complementarity relation}
As previously described, the symbols in the upper and lower strands with the same indexes must be related by the complementarity relation. Unfortunately, this can be checked only at the beginning of the word. Indexes of the symbols in the middle part (anywhere after the first nonterminal) are not known. Thus this check can be understood as an extension of the previous one -- if the word begins with some terminal symbols and there are some symbols in both the upper and lower strands, these symbols can be checked if they are in the relation -- as long as its counterpart is already known.

\subsection{Checking the word correspondence to a regular expression}
It is possible to generate a regular expression that represents the current word. Each non-terminal serves as a wild card ($.*$). Each terminal in the upper strand stands for itself. Lower strand is ignored. This expression must be matchable to the input string, otherwise it is not possible to generate it from the current branch. For instance, if the word is this:
$$\wkpair{abc}{f}N_1\wkpair{d}{gh}N_2\wkpair{e}{i}N_3$$

The resulting regular expression will be: $\verb/^abc.*d.*e/$. The symbols $abc$ must be at the beginning (therefore the \verb/^/ denoting beginning of the expression); then it is not known what will be generated by the non-terminal $N_1$ -- therefore the wildcard; then there will have to be a symbol $d$; another wildcard for non-terminal $N_2$; symbol $e$; and then anything. Starting non-terminal can be represented by omitting the symbol \verb/^/ denoting the beginning of the string. Ending non-terminal can be represented by omitting the symbol \verb/$/ denoting the end of the string.

It is possible to come up with some more checks that could identify a dead end in the search tree. The disadvantage of any check is the computing power that has to be used for any node that is generated and analysed. If some checks are unlikely to significantly trim the tree and/or are complicated to compute, it is not clear if they will improve the actual performance of the algorithm.

\subsection{Examples}
Let us consider a grammar with no $\lambda$-rules with the complementarity relation being an identity, input string \verb/'abcd'/  and a following words:

\begin{enumerate}
\item{
$$\wkpair{a}{ab} N_1 \wkpair{\lambda}{cd} N_2 \wkpair{\lambda}{e}$$
The input string can never be generated from this word because the fragments of the lower strand are too long already -- it has five symbols and the input string only has four.
}
\item{
$$\wkpair{ab}{ab} N_1 N_2 \wkpair{\lambda}{d} N_3 N_4$$
This word would be promising if there had been some lambda rules. Since there are not, the word contains too many non-terminals. Each of them is going to generate at least one terminal symbol and only three symbols are missing ($c$ and $d$ in the upper strand and $c$ in the lower strand). Inevitably, there will be at least one symbol too many.
}
\item{
$$\wkpair{abd}{\lambda} N_1 \wkpair{\lambda}{ab} N_2$$
Regarless of what canb be generated from $N_1$ and $N_2$, the upper strand will always have to begin with symbols $abd$. There is no way how to insert $c$ between $b$ and $d$. Therefore the input string can never be generated from here.
}
\item{
$$\wkpair{abc}{ac} N_1 \wkpair{\lambda}{d} N_2$$
The upper strand looks promising as it starts with the same symbols $abc$ as the input string. But the lower strand starts with $ac$. The first symbol pair $(a/a)$ passes the check, the second one $(b/c)$ does not. The third symbol in the upper strand -- $c$ cannot be related to any symbol -- it has no counterpart, yet. The check was always going to end with the second symbol pair.
}
\item{
$$N_1 \wkpair{b}{\lambda} N_2 \wkpair{a}{\lambda} N_3$$
Whatever is generated from the non-terminals $N_1$, $N_2$, $N_3$ the upper strand will always keep the order of symbols -- first symbol $b$ and then symbol $a$ (with potentially some symbol before, in between and after). That can never result in the string $abcd$.
}

\section{Heuristics and optimizations for generating nodes}
While testing the performance of the search algorithm, optimization which showed to be the most significant was a simple one -- to always consider only the leftmost generation. That enables some of the tree trimming optimizations described previously to be much more effective, because they check the beginning of the strands.

Following section will describe heuristics that help to pick more promising rule first. Such heuristics can only be effective if the answer to the membership is positive. Unfortunately, if it is negative, it does not help that the algorithm eliminates the more promising branches of the tree first. Eventually, it will have to search through all possible states anyway in order to make sure that there is no solution.

The following heuristics always consider a given word and assign a number to it. The lower the number the sooner this word will be picked as the next tree node to be analysed.

\begin{itemize}
  \item{No heuristic -- the evaluation of the word is always 0. This is used for comparision to the other heuristics.}
  \item{Aversion to non-terminals -- the evaluation is equal to the count of non-terminals in the word}
  \item{Weighted aversion to non-terminals -- each non-terminal has a precalculated weight, which is the minimum amount of rules that must be used in order to generate only terminals from it. The evaluation is equal to the sum of the weights of all non-terminals in the word.}
  \item{Prefer longest prefix matching the input string -- }
\end{itemize}



\end{enumerate}
% \section{Running non-deterministic WKA with BFA}

% \section{Generating strands using CF WK grammar}

\chapter{Implementation of the algorithm}

\chapter{Testing the algorithm and comparison to WK-CYK}

\section{WK-grammars used for testing}

For the testing of the tree search algorithm and the WK-CYK algorithm, following Watson-Crick grammars have been used. Unless stated otherwise, the set of non-terminals and the set of terminals will simply be defined by the rules -- all the uppercase letters are non-terminals of the grammar and all the lowercase letters are terminals. The starting non-terminal will be $S$ and the complementarity relation is going to be identity. With these specifications in mind the grammar can be defined by the rules only.

\begin{enumerate}
  \item{
    $$S \rightarrow \wkpair{a}{a} \:|\: S S S$$
    The accepted language is: $a(aa)^*$
  }

  \item{
    $$S \rightarrow \wkpair{a}{\lambda} S \:|\: \wkpair{a}{\lambda} A$$
    $$A \rightarrow \wkpair{b}{a} A \:|\: \wkpair{b}{a} B$$
    $$B \rightarrow \wkpair{\lambda}{b} B \:|\: \wkpair{\lambda}{b}$$


    The accepted language is: $a^nb^n$ where $n \geq 1$
  }

  \item{
    $$S \rightarrow \wkpair{r}{\lambda} S \:|\: \wkpair{r}{\lambda} A$$
    $$A \rightarrow \wkpair{d}{r} A \:|\: \wkpair{d}{r} B$$
    $$B \rightarrow \wkpair{u}{d} B \:|\: \wkpair{u}{d} C$$
    $$C \rightarrow \wkpair{r}{u} C \:|\: \wkpair{r}{u} D$$
    $$D \rightarrow \wkpair{\lambda}{r} D \:|\: \wkpair{\lambda}{r}$$

    The accepted language is: $r^nd^nu^nr^n$ where $n \geq 1$
  }

  \item{
    $$S \rightarrow \wkpair{a}{\lambda} S \wkpair{b}{\lambda} \:|\: \wkpair{a}{\lambda} A \wkpair{b}{\lambda}$$
    $$A \rightarrow \wkpair{c}{a} A \:|\: \wkpair{\lambda}{c} B \wkpair{\lambda}{b}$$
    $$B \rightarrow \wkpair{\lambda}{c} B \wkpair{\lambda}{b} \:|\: \wkpair{\lambda}{\lambda}$$

    The accepted language is: $a^nc^nb^n$ where $n \geq 1$
  }

  \item{
    $$S \rightarrow \wkpair{a}{\lambda} S \:|\: \wkpair{a}{\lambda} A$$
    $$A \rightarrow \wkpair{b}{\lambda} A \:|\: \wkpair{b}{\lambda} B$$
    $$B \rightarrow \wkpair{c}{a} B \:|\: \wkpair{c}{a} C$$
    $$C \rightarrow \wkpair{d}{b} C \:|\: \wkpair{d}{b} D$$
    $$D \rightarrow \wkpair{\lambda}{c} D \:|\: \wkpair{\lambda}{d} D \:|\: \wkpair{\lambda}{\lambda}$$

    The accepted language is: $a^nb^mc^nd^m$ where $n, m \geq 1$
  }

  \item{
    $$S \rightarrow \wkpair{a}{\lambda} S \:|\: \wkpair{b}{\lambda} S \:|\: \wkpair{c}{\lambda} A$$
    $$A \rightarrow \wkpair{a}{a} A \:|\: \wkpair{b}{b} A \:|\: \wkpair{\lambda}{c} B$$
    $$B \rightarrow \wkpair{\lambda}{a} B \:|\: \wkpair{\lambda}{b} B \:|\: \wkpair{\lambda}{\lambda}$$

    The accepted language is: $wcw$ where $w \in \{a, b\}^*$
  }

  \item{
    $$S \rightarrow \wkpair{a}{\lambda} S \wkpair{a}{a} \:|\: \wkpair{a}{\lambda} A \wkpair{a}{a} $$
    $$A \rightarrow \wkpair{bb}{a} A \:|\: \wkpair{bbb}{a} A \:|\: \wkpair{\lambda}{b} B$$
    $$B \rightarrow \wkpair{\lambda}{b} B \:|\: \wkpair{\lambda}{\lambda}$$

    The accepted language is: $a^nb^ma^n$ where $2n \leq m \leq 3n$
  }

  \item{
    $$S \rightarrow \wkpair{a}{t} S \:|\: \wkpair{t}{a} S \:|\: \wkpair{g}{c} S \:|\: \wkpair{c}{g} A$$
    $$A \rightarrow \wkpair{c}{g} A \:|\: \wkpair{a}{t} S \:|\: \wkpair{g}{c} S \:|\: \wkpair{t}{a} B$$
    $$B \rightarrow \wkpair{c}{g} A \:|\: \wkpair{a}{t} S \:|\: \wkpair{t}{a} S \:|\: \wkpair{g}{c} C$$
    $$C \rightarrow \wkpair{a}{t} C \:|\: \wkpair{t}{a} C \:|\: \wkpair{g}{c} C \:|\: \wkpair{c}{g} C \:|\: \wkpair{\lambda}{\lambda}$$

    The complementarity relation of this grammar is: $\{(a, t), (t, a), (c, g), (g, c)\}$

    The accepted language is: $(\{a,t,c,g\}^*ctg\{a,t,c,g\}^*)^*$
  }

  \item{
    $$S \rightarrow \wkpair{l}{\lambda} S \:|\: \wkpair{l}{\lambda} A$$
    $$A \rightarrow \wkpair{r}{l} A \:|\: \wkpair{r}{l} B$$
    $$B \rightarrow \wkpair{l}{r} B \:|\: \wkpair{\lambda}{r} B \:|\: \wkpair{\lambda}{\lambda} \:|\: A$$

    The accepted language is: $(l^n r^n)^k$ where $n$ does not increase \todo{explain this}
  }

  \item{
    $$S \rightarrow S S \:|\: \wkpair{a}{a} S \wkpair{b}{b} \:|\: \wkpair{a}{\lambda} S \:|\: \wkpair{a}{\lambda} A$$
    $$A \rightarrow \wkpair{b}{a} A \:|\: \wkpair{b}{a} B \:|\: \wkpair{b}{a}$$
    $$B \rightarrow \wkpair{\lambda}{b} B \:|\: \wkpair{\lambda}{b} \:|\: B B \:|\: \wkpair{a}{a} S \wkpair{b}{b} \:|\: \wkpair{a}{\lambda} S \:|\: \wkpair{a}{\lambda} A$$

    The accepted language is: $w: \#_a = \#_b$ and for any prefix of $w: \#_a \geq \#_b$ ($\#_a, \#_b$ are counts of symbols $a$ and $b$)
  }

  \item{
    $$S \rightarrow B L \:|\: R B$$
    $$L \rightarrow B L \:|\: A$$
    $$R \rightarrow R B \:|\: A$$
    $$A \rightarrow B A B \:|\: \wkpair{2}{2}$$
    $$B \rightarrow \wkpair{0}{0} \:|\: \wkpair{1}{1}$$

    The accepted language is: $x2y$ where $x, y \in \{0, 1\}^* $ and $|x| \neq |y|$
  }

  \item{
    $$S \rightarrow T \:|\: T \wkpair{p}{p} S$$
    $$T \rightarrow F \:|\: F T$$
    $$F \rightarrow \wkpair{e}{e} \:|\: W \:|\: \wkpair{o}{o} T \wkpair{p}{p} S \wkpair{c}{c} \:|\: X \wkpair{s}{s} \:|\: \wkpair{o}{o} Y \wkpair{c}{c} \wkpair{s}{s}$$
    $$X \rightarrow \wkpair{e}{e} \:|\: \wkpair{l}{l} \:|\: \wkpair{0}{0} \:|\: \wkpair{1}{1}$$
    $$Y \rightarrow T \wkpair{p}{p} S \:|\: F \wkpair{d}{d} T \:|\: X \wkpair{s}{s} \:|\: \wkpair{o}{o} Y \wkpair{c}{c} \wkpair{s}{s} \:|\: Z Z$$
    $$W \rightarrow \wkpair{l}{l} \:|\: Z$$
    $$Z \rightarrow \wkpair{0}{0} \:|\: \wkpair{1}{1} \:|\: Z Z$$

    The accepted language is regular expressions over symbols 0 and 1 with parenthesis ($o$ for opening and $c$ for closing parenthesis) operators $+$ (p), $*$ (s), $\cdot$ (d) and symbols $\emptyset$ (e), $\varepsilon$ (l)
  }
\end{enumerate}

\section{Methods of testing}
For each of the grammars various input strings have been used. It is important to differentiate between the positive cases -- the inputs which are in the given language -- and negative cases.
For each input, three types of tests are then executed:
\begin{itemize}
  \item{Try to generate the input by the grammar using all of the available heuristics.}
  \item{First transform the grammar to WK-CNF and then try to generate the input by the grammar using all of the available heuristics. In case the grammar was in tyhe WK-CNF already, this set of tests is redundant, but most grammars used for testing are not.}
  \item{Transform the grammar to WK-CNF and try to accept the input using the WK-CYK algorithm.}
\end{itemize}

The most important metric is the time to reach the solutioin. Secondary metric is the amount of nodes that were analysed (this is only applicable to the tree search algorithm, not to WK-CYK). There is a limit of 20 seconds, if the solution is not found within this limit, the algorithm timeouts with no answer.

Each test is repeated seven times and the average is taken as a result. These tests aim to answer the followinf questions:
\begin{itemize}
  \item{which algorithm is faster and more practical in real use}
  \item{what is the practical complexity of the algorithms}
  \item{what are the maximum lengths of inputs which can be solved in resonable time}
\end{itemize}

\section{Testing results}

\section{Testing conclusions}


\chapter{Conclusion}
